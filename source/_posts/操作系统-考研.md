---
title: 操作系统-考研
date: 2021-07-02 20:00:30
tags:
- 考研笔记

---



> 考研真是麻烦的事啊啊啊啊

# 操作系统引论

## 操作系统的目标与作用

### 操作系统的目标

1. 有效性
   1. 提高系统资源利用率
   2. 提升系统吞吐量
   3. 方便性
2. 可扩充性
3. 开放性：符合国际标准，兼容性强

### 操作系统的作用

1. OS作为用户和计算机硬件系统之间的接口

   1. 命令方式
   2. 系统调用方式
   3. GUI

2. OS作为计算机系统资源的管理者

   处理器，存储器，I/O设备以及信息

3. OS实现了对计算机资源的抽象

   隐藏硬件细节与功能实现的细节

### 推动操作系统发展的主要动力

1. 不断提高计算机资源的利用率
2. 方便用户
3. 器件的不断更新换代
4. 计算机体系结构的不断发展

## 操作系统的发展过程

### 无操作系统的计算机系统

此处硬件对应真空管

1. 人工操作方式

   输入-计算-输出

   缺点：

   1. 用户独占全机
   2. CPU等待人工操作

2. 脱机输入输出方式

   输入设备-外围机-磁盘-主机-磁盘-外围机-输出设备，其中磁盘与外围机可看作I/O缓冲区

   优点：

   1. 减少了CPU空闲时间
   2. 提高了I/O速度

### 单道批处理系统

此处硬件对应晶体管

1. 单道批处理系统处理过程

   输入设备可以输入作业，监督程序**自动在作业完成后开始下一个作业**，内存中只有一个作业

2. 单道批处理系统的特征

   自动性，顺序性，单道性

### 多道批处理系统

此处对应硬件小规模集成电路

1. 多道程序设计的基本概念

   外存中存储多个作业，作业调度程序按一定算法选择若干个作业调入内存。

   好处：

   1. 提高CPU的利用率，**系统在当前程序等待I/O时处理下一个作业**
   2. 可提高内存与I/O设备利用率
   3. 提高系统吞吐量

2. 多道批处理系统的优缺点

   1. 资源利用率高
   2. 系统吞吐量大
   3. 平均周转时间长
   4. 无交互能力

3. 多道批处理系统需要解决的问题(对应了本书讨论的问题)

   1. 处理机管理问题
   2. 内存管理问题
   3. I/O设备管理问题
   4. 文件管理问题
   5. 作业管理问题

### 分时系统

机器的分配过程是透明的。每个终端对用户而言就是一台可交互的计算机

1. 分时系统的产生

   用户需求：

   1. 人机交互
   2. 共享主机
   3. 便于用户上机

2. 分时系统实现的关键问题

   注：由于是交互式的

   1. 及时接受
   2. 及时处理，调度的粒度由作业下降至时间片

3. 分时系统的特征

   1. 多路性
   2. 及时性
   3. 交互性

### 实时系统

1. 应用需求

   1. 实时控制，对于采集到的数据的及时处理并控制
   2. 实时信息处理

2. 实时任务

   按任务是否呈现周期性来划分：周期性实时任务，非周期性实时任务

   根据对截止时间的要求来划分：

   1. 硬实时系统：不在规定时间完成会有难以预测的后果
   2. 软实时任务

3. 实时系统和分时系统特征的比较

   1. 多路性：体现在对多个数据的处理
   2. 独立性：用户服务。信息采集与对象控制的独立性
   3. 及时性：截止时间的要求
   4. 交互性：只提供特定的专用服务
   5. 可靠性

### 微机操作系统的发展

1. 单用户单任务操作系统

   一个用户上机，且只允许用户程序作为一个任务运行

   一般都为8bit和16bit机，例如CP/M与MS-DOS

2. 单用户多任务操作系统

   一个用户上机，但允许用户把程序分为若干个任务，是他们并发执行

   例如：Windows

3. 多用户多任务操作系统

   多个用户通过各自的终端使用同一台机器。共享主机系统的各种资源。而每个用户程序又可进一步分为几个任务，是它们能并发执行

   例如：UNIX

## 操作系统的基本特性

### 并发性

1. 并行与并发

   并行：一个时刻运行多个程序

   并发：一个时间间隔内运行多个程序

2. 引入进程

3. 引入线程

### 共享性

系统资源供多个并发执行的进程共同使用

1. 互斥共享方式

   把在一段时间内只允许一个进程访问的资源称为临界资源或独占资源

2. 同时访问方式

### 虚拟技术

把一个物理实体变为若干个逻辑上的对应物

1. 时分复用技术

   按时间轮流使用

   1. 虚拟处理机技术
   2. 虚拟设备技术

2. 空分复用技术

   空间分割为不同区域

   1. 虚拟磁盘技术
   2. 虚拟存储器技术

### 异步性

进程是以人们不可预知的速度向前推进，此即进程的异步性。

## 操作系统的主要功能

### 处理器管理功能

1. 进程控制：创建，撤销与状态转化

2. 进程同步

   进程互斥方式，对于进程访问临界资源

   进程同步方式，对于相互合作去完成共同任务的诸线程

3. 进程通信

4. 调度

   作业调度与进程调度

### 存储器管理功能

1. 内存分配

   分配机制应该有：

   1. 内存分配数据结构
   2. 内存分配功能
   3. 内存回收功能

2. 内存保护，访问控制

3. 地址映射，虚地址到实地址

4. 内存扩充，虚拟存储技术

### 设备管理功能

1. 缓冲管理

   由于CPU的高速与I/O的低速，需要两者间设立缓冲区

2. 设备分配

3. 设备处理，实现CPU和设备控制器之间的通信

### 文件管理功能

1. 文件存储空间的管理
2. 目录管理
3. 文件的读/写管理和保护

### 操作系统与用户之间的接口

1. 用户接口，例如命令
   1. 联机用户接口
   2. 脱机用户接口，联机脱机的区别在于即时通信
   3. 图形用户接口
2. 程序结构，例如shell编程

## OS结构设计

### 传统的操作系统结构

1. 无结构操作系统
2. 模块化结构OS
3. 分层式结构OS

C/S模式

面向对象的程序设计

### 微内核OS结构

1. 基本概念

   1. 足够小的内核：只完成操作系统最基本的部分

   2. 基于C/S模式：绝大部分功能为进程提供

   3. 机制与策略分离

      机制，某一功能的具体执行机构

      策略，用算法组织机制，优化功能或实现新功能

   4. 采用面向对象技术

2. 基本功能

   1. 进程管理
   2. 低级存储器管理，例如地址映射，页表机制
   3. 中断与陷入处理

3. 优点

   提高了可拓展性，可靠性，可移植性。提供了对分布式系统的支持，融入了面向对象技术

4. 存在的问题：效率不高

# 进程管理

## 进程的基本概念

### 程序的顺序执行及其特征

顺序性，封闭性，可再现性

### 前驱图 DAG

### 程序的并发执行及其他特征

1. 程序的并发执行

   并发执行可能导致不按照原有顺序执行

2. 程序并发执行时的特征

   1. 间断性，走走停停
   2. 失去封闭性，不再独享资源
   3. 不可再现性，不按原有顺序执行

### 进程的特征与状态

1. 进程的特征与定义

   为使程序能够并发执行，且为了对并发执行的程序加以描述和控制而引入进程

   1. 结构特点：程序段，数据段和PCB，其中PCB是进程存亡的关键
   2. 动态性，进程的实质是进程实体的一次执行过程
   3. 并发性
   4. 独立性，不建立PCB就无法运行
   5. 异步性

   定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位

2. 进程的三种基本状态：就绪，执行和阻塞

3. 挂起状态

4. 创建状态与中止状态

### PCB

1. 作用

   记录了操作系统所需的，用于描述进程当前情况以及控制进程运行的全部信息，PCB是进程存在的唯一标志。

2. 信息

   1. 进程标识符
   2. 处理机状态，寄存器
   3. 进程调度信息，状态，优先级，阻塞原因

3. 组织方式

## 进程控制

原语是若干条指令组成的用于完成一定功能的具有原子性的一个过程

### 进程的创建

1. 进程图，描述父子关系，子进程能够继承父进程所拥有的资源

2. 创建进程的事件：用户登录，作业调度，提供服务和应用请求

3. 进程的创建

   申请空白PCB-分配资源-初始化PCB-插入进就绪队列

### 进程的中止

1. 引起进程终止的事件：正常结束，异常结束和外界干预

2. 进程的终止过程

   读取状态-若正在执行，则终止执行，重新调度-终止子孙进程-归还资源-移除队列

### 进程的阻塞与唤醒

1. 引起进程阻塞和唤醒的事件：请求系统服务，启动某种操作，新数据尚未到达，无新工作可做

2. 进程阻塞过程

   进程主动调用block原语-若处于执行状态则停止执行-改变PCB内状态-插入阻塞队列-转调度程序

3. 进程唤醒过程

   有关进程调用唤醒原语wakeup-从阻塞队列中移出-改变PCB内状态为就绪-插入就绪队列

### 进程的挂起与激活

1. 挂起

   自己或父进程请求，系统将利用suspend原语

   过程：就绪变为静止就绪，活动阻塞变为静止阻塞

2. 激活

   父进程或用户进程请求，系统使用active原语

## 进程同步

主要任务：对多个相关进程在执行次序上进行协调，以便并发执行的诸进程之间能够有效地共享资源和相互合作从而使程序的执行具有可再现性

### 基本概念

1. 两种形式的制约关系

   间接相互制约关系：共享某种系统资源

   直接相互制约关系：源于进程间合作

2. 临界资源

3. 临界区

   每个进程种访问临界资源的那段代码

4. 同步机制应遵循的规则

   空闲让进，忙则等待，有限等待，让权等待（不能进入临界区时，立即释放处理机）

### 信号量机制

1. 整型信号量，wait(S)，signal(S)两个原子操作也成为PV操作

2. 记录型信号量，多个进程等待同一临界资源，需要一个进程链表指针

3. AND型信号量，访问多个临界资源，防止发生死锁，必须同时申请所有资源

4. 信号量集，多种资源，且每种资源可能有多个

   Swait(S,d1,d1)每次申请d1个S资源，当S资源小于d2个不予分配

### 信号量的应用

1. 利用信号量实现进程互斥（基本功能）
2. 利用信号量实现前趋关系（利用signal()释放初始量小于1的信号量）

### 管程机制

1. 定义

   Hansan:一个管程定义了一个数据结构和能为并发进程所执行(在该数据结构上)的一组操作，这组操作能同步进程和改变管程中的数据。

   特点：模块化，抽象数据类型和信息隐藏

   和进程的不同：

   1. 管程为公共数据结构
   2. 用于同步
   3. 为了解决共享资源的互斥
   4. 被动工作
   5. 管程不能与其调用者并发
   6. 资源管理模块，没有明显的生存周期

2. 条件变量

   基本与信号量相同。

   当P唤醒Q时：
   P紧急等待，Q继续，直到Q退出或等待；(Hoare)
   	Signal and urgent wait
   Q等待，P继续，直到P退出或等待；(Java)
   	Signal and continue
   	被唤醒进程需要重新检查等待条件,可能再次等待.
   唤醒是管程中可执行的最后一个操作。(Hansen)
   	Signal and leave

## 经典进程同步问题

### 生产者-消费者问题

1. 记录型信号量

   mutex用于管理缓冲池互斥，empty用于空队列的同步，full用于满队列的同步

2. AND信号量

   与上文相同，用Swait(empty,mutex)等替代原有操作

3. 管程

   定义整个缓冲池，信号量与放置，取走与初始化操作，

### 哲学家用餐问题

1. 记录型信号量

   可能存在死锁

2. AND信号量

   一次申请两只筷子

3. 管程

### 读者-写者问题

1. 记录型信号量

   Wmute用于读写互斥，当ReadCount=0时，读者才需要Wait(Wmutex)，ReadCount=1时才需要Signal(Wmutex)。

   Rmutex用于对ReadCount的互斥。

2. 信号量集

   此时问题增加约束，最多同时容纳Rn个读者，

   L用于同步剩余读者容量

   mx用于读写互斥

## 进程互斥

信号量机制的缺点：

1. 效率低，每次只能对一个数据操作
2. 通信对用户不透明，需要用户参与设计数据结构

### 进程通信的类型

1. 共享存储器系统

   共享数据结构或共享存储区进行通信。

   1. 共享数据结构，需要程序员设计数据结构，增加了程序员负担
   2. 共享存储区

2. 信号传递系统

   以格式化的消息(message)为单位传输，微内核中常用，可分为直接通信与间接通信方式

3. 管道通信

   管道：连接一个读进程和一个写进程以实现它们之间通信的一个共享文件。

   需要互斥，同步和确定对方存在三个功能。

### 消息传递通信的实现

1. 直接通信方式

   直接通过Send(Receiver,message)和Receive(Sender,message)收发消息

2. 间接通信方式

   用信箱作为共享数据结构的实体，用于存放消息。

   1. 私有信箱：自己rw,其他w
   2. 公有信箱：操作系统创建，核准进程使用，系统运行期间都存在
   3. 共享信箱：某进程创建，可授权给别的的进程。

### 消息传递系统实现的若干问题

1. 通信链路

   面对连接和面对无链接

2. 消息的格式

   定长or变长，有无消息头

3. 进程同步方式

   1. 发送进程阻塞，接收进程阻塞

      也称为汇合，用于紧密同步

   2. 发送进程不阻塞，接收进程阻塞

      应用最广，发送进程不阻塞以实现快速将多个消息发给多个目标

   3. 发送进程接收进程都不阻塞

      较常见，由于消息队列的存在，只要消息队列非空或非满就不阻塞

### 消息缓冲队列通信机制

1. 消息缓冲队列通信机制中的数据结构

   消息缓冲区：链表实现

   PCB有关通信的数据项：要存储消息队列的互斥信号量与资源信号量

2. 发送原语

   按照消息大小申请缓冲区，复制入发送去-获取接收进程PID-插入缓冲区（互斥）

3. 接受原语

## 线程

### 线程的基本概念

1. 线程的引入

   进程：可拥有资源的独立单位，同时是可独立调度和分配的基本单位。由于拥有资源，进程的创建、撤销和切换代价过大。故而让进程成为资源分配的单位，线程作为调度的单位

2. 线程和进程的比较

   在引入了线程的操作系统中，通常一个进程都拥有若干个线程、

   1. 调度

      在同一进程中，线程的切换不会导致进程的切换，但不同的进程的线程切换时，会导致进程的切换

   2. 并发性

      一个进程有多个线程并发，减少了进程被阻塞的几率，提高了系统吞吐量

   3. 拥有资源

      一般而言，线程自己不拥有系统资源

   4. 系统开销

      由于不拥有资源（拥有资源少），保存的现场信息少，系统开销小

3. 线程的属性

   1. 轻型实体
   2. 独立调度和分派的基本单位
   3. 可并发执行
   4. 共享进程资源

4. 线程的状态

   1. 状态参数：寄存器状态，堆栈，线程运行状态，优先级，线程专用存储器，信号屏蔽
   2. 线程运行状态：执行-就绪-阻塞

5. 线程的创建和终止

   创建：存在初始线程

   终止： 自愿退出，错误或被其他进程终止。终止后并不立即释放所占有的资源，而在其他线程执行分离函数后才与资源分离

6. 多线程OS中的进程

   作为资源分配的单位，可包括多个进程（最少一个），不再是一个可执行的实体

###  线程间的同步和通信

1. 互斥锁

2. 条件变量

   互斥锁用于互斥进入数据段，条件变量用于线程的长期等待。进入不等同于占有，减少死锁可能性

3. 信号量机制

   公有信号量：OS创建

   私有信号量：进程创建，进程被撤销时无法通知所有进程，故而存在风险

### 线程的实现方式

1. 内核支持线程

   线程操作都在内核空间内实现，内核空间存在线程控制块，内核知道线程的存在

   优点：

   1. 内核能同时调度一个进程中的多个线程并行执行
   2. 若进程中的一个线程被阻塞可以调度进程内的另一个线程
   3. 内核支持线程具有很小的数据结构和堆栈，线程切换快，开销小
   4. 内核本身也可多线程实现，提高系统的执行速度和效率

   缺点：线程切换时需要从用户态转到内核态，系统开销大

2. 用户级线程

   线程操作与内核无关，内核完全不知道用户级线程的存在，调度仍以进程为单位，故而进程线程越多，每个线程被分配的进程时间越少。

   优点：

   1. 进程切换不需要转换到内核空间
   2. 调度算法可以是进程专有的
   3. 实现与操作系统无关

   缺点：

   1. 线程被阻塞时整个进程都会被阻塞
   2. 由于进程每次只被分配到一个处理机，故而同一时刻进程内只有一个线程在运行

3. 组合方式

### 线程的实现

1. 内核支持线程的实现

   内核空间创建任务数据区PTDA，其中存储TCB。（进程变为了管理进程资源的PTDA）

2. 用户级线程的实现

   1. 运行时系统

      相当于一个放置于用户态的线程控制系统，是管理和控制线程的函数的集合，因此线程的切换不再需要进入内核。

   2. 内核控制线程

      上文提及用户级线程一个进程内的线程因为系统调用整个进程都将被阻塞，为了解决这个矛盾，内核提供了多个接口用于为进程中的线程提供服务，此接口被称为轻型进程LWP。当线程需要访问内核空间时将自身装载进LWP，进入内核空间后变为内核级线程。而原进程将不被阻塞。

3. 用户级线程和内核控制线程的连接

   一对一，多对一，多对多

# 处理机调度与死锁

## 处理机调度的层次

1. 作业调度（高级调度）
2. 存储器调度（中级调度）
3. 进程调度（低级调度）

频率：低级调度>中级调度>高级调度。越高频调度算法就应该越简单

### 高级调度

1. 作业与作业步

   1. 作业：程序，数据和作业说明书
   2. 作业步：每个作业都需要经过若干个相对独立又相互关联的顺序加工步骤才能得到结果，其中每一个加工步骤称为一个作业步。编译作业步-连结装配作业步-运行作业步
   3. 作业流：有次序地存放若干个位于外存的作业的队列

2. 作业控制快

   包含标识，用户信息，作业类型，作业状态，调度信息，资源需求等信息

   进入系统时，系统为每个作业建立一个JCB，根据作业类型分配在不同的后备队列，由作业调度程序调度，被调度到的作业将被进入内存

3. 作业调度

   用户希望自己作业平均周转时间尽可能少，系统希望平均周转时间尽可能少

   需要考虑：决定接纳多少个作业，决定接纳哪些作业

### 低级调度

1. 低级调度的功能
   1. 保存处理机的县城信息
   2. 按某种算法选取进程
   3. 把处理器分配给进程
2. 进程调度中的三个基本机制
   1. 排队器
   2. 分派器
   3. 上下文切换机制
3. 进度调度方式
   1. 非抢占方式：当前进程在自愿退出后阻塞后才归还处理机
   2. 抢占方式：调度程序暂停某个正在执行的进程，将它的处理机重新分配，原则：优先权原则，短作业优先原则，时间片原则

### 中级调度

为了节省内存，将暂时用不到的进程挂起，即调至外存等待。

## 调度队列模型对调度准则

### 调度队列模型

1. 仅有进程调度的调度队列模型
2. 具有高级和低级调度的调度队列模型
3. 同时具备三级调度的调度队列模型

### 选择调度方式和调度算法的若干准则

1. 面向用户的准则

   1. 周转时间短

      周转时间：作业提交到系统到作业完成为止的时间间隔

      带权周转时间：作业周转时间和系统为它提供服务的时间之比

   2. 响应时间快

   3. 截止时间保证

   4. 优先权原则

2. 面向系统的准则

   1. 系统吞吐量高
   2. 处理机利用率好
   3. 各类资源平衡利用

## 调度算法

调度的实质是一种资源分配

### 先来先服务和短作业优先调度算法

1. 先来先服务调度算法，有利于长作业
2. 短作业优先调度算法，有利于短作业，长作业可能被饿死

### 高优先权优先调度算法

1. 优先权调度算法的类型：非抢占式和抢占式

2. 优先权的类型

   静态优先权：创建进程时确定，运行时不变

   1. 进程类型，系统进程>用户进程
   2. 进程对资源的需求，占有资源少优先
   3. 用户要求

   动态优先权：可变的

3. 高响应比优先调度算法
   $$
   R_p = \frac{等待时间+要求服务时间}{要求服务时间}=\frac{响应时间}{要求服务时间}
   $$
   可以体现：

   1. 短作业优先
   2. 等待时间越长，优先权越高，即先来先服务
   3. 对于长作业，等待时间越长优先级也会越高

### 基于时间片的轮转调度算法

1. 时间片轮转法
   1. 基本原理：先按先来先服务的原则排成一个队列，获得一次时间片后将进程移动至队列尾部
   2. 时间片大小的确定：过短增加系统开销，过长无法满足交互式用户的需求，可取的大小是也略大于一次典型的交互所需要的时间
2. 多级反馈队列调度算法
   1. 多个队列，越靠后的队列优先级越低但获得的时间片越长
   2. 新进程先进入第一个队列的尾部，获得时间片后移动至下一个队列
   3. 只有优先权高的队列为空时才运行优先权低的队列中的进程
3. 多级反馈队列调度算法的性能
   1. 终端型作业用户，若在第一个队列完成则可满意
   2. 短批处理作业用户，周转时间短
   3. 长批作业处理用户，不会被饿死

## 实时调度

### 实现实时调度的基本条件

1. 提供必要的信息

   就绪时间，开始截止时间和完成截止时间，处理时间，资源要求，优先级

2. 系统处理能力强
   $$
   假设系统中由m个周期性的硬实时任务，他们的处理时间可以表示为C_i，周期时间表示为P_i，处理机数量N\\
   \sum_{i=1}^{m}\frac{C_i}{P_i}\le N
   $$

3. 采用抢占式调度机制

4. 具有快速切换机制：对外部中断的快速响应能力。快速的任务分派能力

### 实时调度算法的分类

1. 非抢占式调度算法：非抢占式轮转调度算法，非抢占式优先调度算法
2. 抢占式调度算法
   1. 基于时钟中断的抢占式优先权调度算法，时钟中断到来时，调度算法才剥夺当前任务的执行
   2. 立即抢占的优先权调度算法

### 常用的几种实时调度算法

1. 最早截至时间有限即EDF算法

   根据任务的开始截止时间来确定任务的优先级，越早优先权越高

   可抢占也可非抢占，抢占式灵活度更高更不容易错过任务。

2. 最低松弛度优先即LLF算法

   松弛度=剩余时间-运行时间，一般都为抢占式

## 产生死锁的原因与必要条件

### 产生死锁的原因

1. 竞争资源引起的进程死锁
   1. 可剥夺与非剥夺性资源，区别能否强行收回，前者例如内存区，后者比如打印机
   2. 竞争非剥夺性资源可能造成死锁
   3. 竞争临时性资源，比如消息，进程通信可能造成死锁
2. 进程推进顺序不当引起死锁

### 产生死锁的必要条件

1. 互斥条件，即在一段时间内内某资源只由一个进程占用
2. 请求和保持条件，进程保持了至少一个资源，但又提出了新的资源请求
3. 不剥夺条件，资源在未使用完之前不能被剥夺
4. 环路等待条件，存在一个进程-资源的环形链

### 处理死锁的基本方法

1. 预防死锁，打破死锁的必要条件，一般条件过于严格，会降低系统吞吐量
2. 避免死锁，防止系统进入不安全状态，条件较弱
3. 检测死锁
4. 接触死锁，撤销或挂起一些进程

### 预防死锁

互斥条件是设备属性无法避免

1. 摒弃“请求和保持”条件

   进程必须一次性申请所有资源，简单易于实现且很安全，但资源由于可能存在闲置而被严重浪费

2. 摒弃“不剥夺”条件

   当一个保持了某些资源的进程再提出新的资源请求而不能立即得到满足时，必须释放他已经保持了的所有资源。被迫释放可能会造成前段工作的失效

3. 摒弃“环路等待条件”

   为所有资源按类型进程线性排队，并赋予不同的需要，必须严格按照资源需要递增的顺序提出请求。

   限制了新类型设备的增加，请求顺序和使用顺序的不同可能造成资源浪费，对用户编程提出了限制

### 系统安全状态

1. 安全状态

   系统能按照某种进程顺序，来为每个进程分配其所需的资源直至满足每个进程对资源的最大需求，使每个进程都可顺利完成

2. 由安全状态向不安全状态的转换

   如果不按照安全序列分配资源，就有进入不安全状态的可能性

### 利用银行家算法避免死锁

1. 数据结构

   需要记录

   1. 可利用资源向量Available，记录每类资源可用的数量
   2. 最大需求矩阵Max，记录每个进程对每类资源的最大需求量
   3. 分配矩阵Allocation，记录每个进程占有的每类资源的数量
   4. 需求矩阵Need，记录每个进程对每类资源的需求量

2. 银行家算法

   对于每次申请考虑以下问题

   1. 需求是否合法$Request_i[j]\le Need[i,j]$，不合法则出错
   2. 需求是否可满足$Request_i[j]\le Available[j]$，不满足则等待
   3. 试探分配
   4. 执行安全性算法，若结果安全才真的分配，若不安全则不完成此次分配，进程等待

3. 安全性算法

   遍历所有进程，查看是否当前可用资源是否可满足某进程所需的剩余资源，若可满足，则收回该进程持有的所有资源并标记为完成。如果存在进程序列可让所有进程完成，则该分配安全

## 死锁的检测与解除

### 死锁的检测

系统需要保存有关资源的请求与分配信息与检测死锁的有效算法

1. 资源分配图，资源指向进程指进程占用资源，进程指向资源指进程请求资源
2. 死锁定理，与安全性算法相似，若可以满足进程的所有需求，则释放进程所占有的资源
3. 死锁检测中的数据结构，与银行家算法类似

### 死锁的接触

1. 剥夺资源
2. 撤销进程

而这两种方法代价都很大，故而我们可以先预处理出所有进程的撤销代价，每次选取代价最小的进程撤销

# 存储器管理

## 存储器的层次结构

### 多级存储器结构

寄存器-主存-辅存

可细分为

寄存器-（高速缓存-主存-磁盘缓存）-（磁盘-可移动存储介质）

### 主存储器与寄存器

1. 主存储器

   访问速度远低于CPU执行速率，CPU只能冲主存储器中获得指令与数据。

2. 寄存器

   访问最快，能与CPU协调工作，但价格十分昂贵

### 高速缓存与磁盘缓存

1. 高速缓存

   局部性原理，存储部分主存内容，比主存访问速度快

2. 磁盘缓存

   主存上的一个空间，用于暂存磁盘中读出和写入的数据

## 程序的装入和链接

编译-链接-装入模块-装入程序

### 程序的装入

1. 绝对装入方式

   编译程序产生绝对地址的目标代码

2. 可重定位装入方式

   装入时一次完成的，目标地址为装入地址和相对偏移的组合

3. 动态运行时装入方式

   地址转换在真正执行时才进行，用于适配虚拟存储器机制

### 程序的链接

1. 静态链接

   链接时完成，以后不再分开

2. 装入时动态链接

   边装入边链接

3. 运行时动态链接

   真正用到时再装入

## 连续分配方式

### 单一连续分配

用于单用户单任务的从操作系统中，只分为系统区与用户区，用户区全部交给用户

### 固定分区分配

1. 划分分区的方式

   1. 分区大小相等，缺乏灵活性，会造成浪费
   2. 分区大小不等

2. 内存分配

   按分区大小进行排序，并建立一个分区使用表标记分配情况

### 动态分区分配

1. 分区分配中的数据结构

   空闲分区表与空闲分区链

2. 分区分配算法

   1. 首次适应算法，分配一个大小足够的空闲分区，高地址保留了大空闲区，低址会留下碎片 
   2. 循环首次适应算法，从上次找到的空闲分区的下一个空闲分区开始查找，空闲分区更均匀，但缺少大空闲区
   3. 最佳适应算法，分配满足需求的最小空闲分区，碎片过小导致无法使用
   4. 最坏适应算法，分配满足需求的最大空闲分区，产生碎片概率小
   5. 快速适应算法，分类搜索，将空闲分区按照不同大小分为多个链便于检索

3. 分区分配操作

   1. 分配内存，检索与分割
   2. 回收内存，相邻则合并

### 伙伴系统

将空闲分区初始设置为$2^m$个字的空闲区，为进程分配一个长度为n的空间时，令$2^{k-1}\lt n \le2^k$ 寻找长度为$2^k$的空闲分区，若没有则寻找$2^{k+1}$，若仍然没有则寻找$2^{k+2}$，以此类推，直到找到最小的$2^j$长的空闲分区，将$2^k$分配给进程，剩余$2^{j-k}$放入对应链表。回收时，若回收将其放入$2^k$长度对应链表中，若已存在一个$2^k$的空闲区，则合并为$2^{k+1}$长的空闲分区，以此类推

 ### 哈希算法

建立以空间大小为关键字的哈希表用于检索。

### 可重定位分区分配

1. 动态重定位的引入

   当内存空间进行一次紧凑后，程序所在的物理地址发生了变化，为使程序不丢失，以逻辑地址代替物理地址，即重定位

2. 动态重定位的实现

   用重定位寄存器存放一个基址，并以此计算出物理地址

3. 动态重定位分区分配算法

   与非动态的区别在于紧凑时需要修改有关的数据结构

### 对换

1. 对换的引入

   将暂时用不到的进程或程序和数据调到外存以腾出内存空间。如果对换是以进程为单位，则称之为进程对换，如果是以页或段为单位，则称部分对换。

2. 对换空间的管理

   连续分配，分配与回收与动态分区方式相同。

3. 进程的换出与换入

   1. 换出，无足够内存时考虑，优先选择处于阻塞状态且优先级最低的进程移植外存，回收内存并修改PCB。
   2. 换入，系统定时检查所有进程状态，找出就绪但已被换出的进程，将其中换出时间最久的进程换入，直至没有可换出的进程

## 基本分页存储管理方式

将一个进程直接分散地装入到许多不相邻接的分区中。

### 页面与页表

1. 页面
   1. 将一个进程的逻辑地址空间分为若干个大小相等的片称为页面或页，把内存空间分成与页面大小相等的若干个存储块称为物理块或页框
   2. 页面太小，虽然碎片少但页表过长占用内存，页面太大，提高换入换出效率，但碎片大
2. 地址结构，页号+位移量
3. 页表，属于进程，一张用于将页号映射到物理块号的页面映像表

### 地址变换机构

用于将逻辑地址转换为物理地址

1. 基本的地址变换机构

   系统中只设置一个页表寄存器PTR，用于存放页表在内存的基址与页表的长度，而对应的数据存储于PCB中，进程被调度时才将对应数据装入PTR。

   检查越界-页号变换-与位移量结合为物理地址

2. 具有快表的地址变换机构

   CPU没存取一个数据要访问两次内存（页表，数据），为了提升地址变换速度，增设了快表(TLB)，作为页表的一个高速缓冲寄存器，只有在快表中没找到数据才查找页表，并从快表中淘汰一个数据用于存放新数据。局部性原理，快表中查到的概率大概为90% 

### 两级和多级页表

分页过多时，页表项数过多导致占用内存大，而且要求存储空间是连续的。

解决方法：

采用离散分配的方式，或只存放部分页表项到内存

1. 两级页表

   逻辑地址：外部页号，外部页内地址，页内地址。外部页号指向一个作为页表的物理块，减少搜索时间

2. 多级页表

   32位两级，64位三级

## 基本分段存储管理方式

### 分段存储管理方式的引入

目的：

1. 方便编程，将信息按照逻辑关系分离
2. 信息共享，段是逻辑单位，可让程序员将其作为分享的单位
3. 信息保护，信息为单位进行保护
4. 动态增长，适合不断增大的程序、而不需要划分新的单位
5. 动态链接，可以段为单位装入程序，实现动态链接

### 分段系统的基本原理

1. 分段

   逻辑地址分为段号和段内地址，由于段内地址长度固定，段存在最大长度

2. 段表

   段表中的需要存储每个段的长度与基址

3. 地址变换机构

   检查段号是否越界-获取段长与基址-检查段内偏移是否越界-生成物理地址

4. 分页和分段的主要区别

   1. 页是物理单位，为了实现离散分配而存在，为系统服务。段是逻辑单位，含有一组有实际意义的信息，**为程序员服务**
   2. 页大小固定，段大小**可变**
   3. 分页是一维的，程序员只需要知道逻辑地址，而分段是二维的，程序员需要知道是哪个段以及段内地址

### 信息共享

将数据段和程序段分离，当程序被多个用户使用时，只需要给每个用户分配不同的数据段与一个程序段就可为多个用户服务

可重入代码又称为纯代码，是一种运行中不会被改变的代码，只需要把局部数据的存储区与它分离就可做到

### 段页式存储管理方式

1. 基本原理

   每个段分为若干个页（分配的单位变为了页而非字节），逻辑地址=段号+段内页号+页内地址

2. 地址变换过程

   段号是否越界-取得段的页表-页号是否越界-组合物理地址

## 虚拟存储器的基本概念

两种可能出现的问题

1. 作业过大无法全部装入内存
2. 每次只能装入少量的作业，吞吐量下降

### 虚拟存储器的引入

1. 常规存储器管理方式的特征

   一次性：要求把作业一次性地把全部内容装入内存

   驻留性：装入内存后，在运行结束前都需要一直驻留在内存中

2. 局部性原理

   几个论点：

   1. 除了少数转移指令和过程调用指令，大部分是**顺序执行**
   2. 过程调用的深度一般不超过5
   3. 循环结构会使少数代码被反复运行
   4. 对数据结构的处理，使得操作被局限在很小的范围内

   两个方面：

   1. 时间局限性，被运行到的指令在一段时间后可能被再次运行
   2. 空间局限性，被访问的数据单元附近的数据单元可能也会被访问

3. 虚拟存储器的定义

   由于局部性原理，无需将整个程序装入内存，只需要装入部分数据。当所需数据不在内存上而内存已满时需要置换页面。

   虚拟存储器：具有请求调入功能和置换功能，能从**逻辑上**对内存空间加以**扩充**的一种存储器系统

### 虚拟存储器的实现方法

需要实现局部调入的功能，依赖于离散分配的存储管理方式

1. 分页请求系统

   1. 硬件支持

      请求分页的页表机构，页表需要增加若干标识

      缺页中断机构，当发现所需页不在内存中，需要中断调入页面

      地址变换结构，将逻辑地址变为内存或外存的物理地址

   2. 实现请求分页的软件

      实现页面置换和页面调入

2. 请求分段系统
